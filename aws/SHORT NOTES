Amazon EC2 Instances

-General Purpose
-Compute Optimized
-Memory Optimized
-Accelerated Computing
-Storage Optimized



Compute optimized instances are ideal for compute-bound applications that benefit from high-performance processors. Like general purpose instances, you can use compute optimized instances for workloads such as web, application, and gaming servers.

You can also use compute optimized instances for batch processing workloads that require processing many transactions in a single group.
Memory optimized instances are designed to deliver fast performance for workloads that process large datasets in memory. In computing, memory is a temporary storage area. It holds all the data and instructions that a central processing unit (CPU) needs to be able to complete actions. Before a computer program or application is able to run, it is loaded from storage into memory.Suppose that you have a workload that requires large amounts of data to be preloaded before running an application.
Accelerated computing instances

-Floating point number calculations
-Graphics Processing
-Data pattern matching
-Utilize Hardware accelerators

Accelerated computing instances use hardware accelerators, or coprocessors, to perform some functions more efficiently than is possible in software running on CPUs. Examples of these functions include floating-point number calculations, graphics processing, and data pattern matching.
Storage optimized instances
Storage optimized instances are designed for workloads that require high, sequential read and write access to large datasets on local storage. Examples of workloads suitable for storage optimized instances include distributed file systems, data warehousing applications, and high-frequency online transaction processing (OLTP) systems.
 
AMAZON EC2 Purchase Options

-On Demand
-Saving Plans
-Reserved Instances
-Spot Instances
-Dedicated Hosts

On-Demand
On-Demand Instances are ideal for short-term, irregular workloads that cannot be interrupted. No upfront costs or minimum contracts apply. The instances run continuously until you stop them, and you pay for only the compute time you use.


Reserved Instances are a billing discount applied to the use of On-Demand Instances in your account. There are two available types of Reserved Instances:
	· Standard Reserved Instances
	· Convertible Reserved Instances
You can purchase Standard Reserved and Convertible Reserved Instances for a 1-year or 3-year term. You realize greater cost savings with the 3-year option. 

Standard Reserved Instances: This option is a good fit if you know the EC2 instance type and size you need for your steady-state applications and in which AWS Region you plan to run them. 
Convertible Reserved Instances: If you need to run your EC2 instances in different Availability Zones or different instance types, then Convertible Reserved Instances might be right for you. 
The EC2 Instance Savings Plans are a good option if you need flexibility in your Amazon EC2 usage over the duration of the commitment term. You have the benefit of saving costs on running any EC2 instance within an EC2 instance family in a chosen Region (for example, M5 usage in N. Virginia) regardless of Availability Zone, instance size, OS, or tenancy. 
Unlike Reserved Instances, however, you don't need to specify up front what EC2 instance type and size (for example, m5.xlarge), OS, and tenancy to get a discount. 
Spot Instances are ideal for workloads with flexible start and end times, or that can withstand interruptions. Spot Instances use unused Amazon EC2 computing capacity and offer you cost savings at up to 90% off of On-Demand prices.
 
Dedicated Hosts are physical servers with Amazon EC2 instance capacity that is fully dedicated to your use. You can use your existing per-socket, per-core, or per-VM software licenses to help maintain license compliance. You can purchase On-Demand Dedicated Hosts and Dedicated Hosts Reservations. Of all the Amazon EC2 options that were covered, Dedicated Hosts are the most expensive.




Elastic Load Balancing
Elastic Load Balancing is the AWS service that automatically distributes incoming application traffic across multiple resources, such as Amazon EC2 instances. 
A load balancer acts as a single point of contact for all incoming web traffic to your Auto Scaling group.

Monolithic applications and microservices
Suppose that you have an application with tightly coupled components. These components might include databases, servers, the user interface, business logic, and so on. This type of architecture can be considered a monolithic application. 
To help maintain application availability when a single component fails, you can design your application through a microservices approach.
In a microservices approach, application components are loosely coupled. In this case, if a single component fails, the other components continue to work because they are communicating with each other.


When designing applications on AWS, you can take a microservices approach with services and components that fulfill different functions. Two services facilitate application integration: Amazon Simple Notification Service (Amazon SNS) and Amazon Simple Queue Service (Amazon SQS).

 
Amazon Simple Notification Service (Amazon SNS)
Amazon Simple Notification Service (Amazon SNS) is a publish/subscribe service. Using Amazon SNS topics, a publisher publishes messages to subscribers. This is similar to the coffee shop; the cashier provides coffee orders to the barista who makes the drinks.

AWS Lambda
AWS Lambda(opens in a new tab) is a service that lets you run code without needing to provision or manage servers. 
While using AWS Lambda, you pay only for the compute time that you consume. Charges apply only when your code is running

Amazon Elastic Container Service (Amazon ECS)
Amazon Elastic Container Service (Amazon ECS)(opens in a new tab) is a highly scalable, high-performance container management system that enables you to run and scale containerized applications on AWS. 
Amazon Elastic Container Service (Amazon ECS)
Amazon Elastic Container Service (Amazon ECS)(opens in a new tab) is a highly scalable, high-performance container management system that enables you to run and scale containerized applications on AWS. 


AWS Fargate
AWS Fargate(opens in a new tab) is a serverless compute engine for containers. It works with both Amazon ECS and Amazon EKS. 
When using AWS Fargate, you do not need to provision or manage servers. AWS Fargate manages your server infrastructure for you. You can focus more on innovating and developing your applications, and you pay only for the resources that are required to run your containers.

Amazon ECS (Elastic Container Service)
	• AWS's own container orchestration service.
	• Two Launch Types:
		○ ECS on EC2 → You manage EC2 instances (cluster of servers) where containers run.
		○ ECS on Fargate → No server management! AWS handles the infrastructure.
	
	• You define tasks & services (Docker containers), ECS handles scheduling and scaling.
	

Amazon EKS (Elastic Kubernetes Service)
	• Managed Kubernetes (open-source container orchestration).
	• Same as ECS, but for teams familiar with Kubernetes.
	• Two Options:
		○ EKS on EC2 → You manage the worker nodes (EC2 instances).
		○ EKS on Fargate → AWS handles compute (serverless for containers)

Horizontal scaling
We need somehting to distribute the service accordinlyg – ELASTIC LOAD BALANCER

SQS – allows you to decouple system componenets. Messagese remain in queue until theyre comsumed or deleted

We can use AWS Fargate – if we don’t want to manage container, kubernetes. This allows you to run containers on top of SERVER LESS COMPUNTE plateform.

HOW TO CHOOSE REGION? 4 factors
1.Compilance
2.Proximity - How close are you ?
3.Feature Availability 
4.Pricing

An Availability Zone is a single data center or a group of data centers within a Region. Availability Zones are located tens of miles apart from each other. This is close enough to have low latency (the time between when content requested and received) between Availability Zones.

Which statement best describes an Availability Zone?
The correct response option is A single data center or group of data centers within a Region.


· A Region is a geographical area that contains AWS resources.
· An edge location is a data center that an AWS service uses to perform service-specific operations. 
· AWS Outposts is a service that you can use to run AWS infrastructure, services, and tools in your own on-premises data center in a hybrid approach.

Edge locations
An edge location is a site that Amazon CloudFront uses to store cached copies of your content closer to your customers for faster delivery.



Amazon cloudfront uses EDGE LOCATION to help accelerate communications with users no matter where they are all around the world 


AWS management console
-Test environment
-View AWS Bills
-View Monitoring
-Work with non-technical resources

The AWS Management Console is a web-based interface for accessing and managing AWS services. You can quickly access recently used services and search for other services by name, keyword, or acronym. The console includes wizards and automated workflows that can simplify the process of completing tasks.

You can also use the AWS Console mobile application to perform tasks such as monitoring resources, viewing alarms, and accessing billing information. Multiple identities can stay logged into the AWS Console mobile app at the same time.

 
To save time when making API requests, you can use the AWS Command Line Interface (AWS CLI). AWS CLI enables you to control multiple AWS services directly from the command line within one tool. AWS CLI is available for users on Windows, macOS, and Linux. 
 
To save time when making API requests, you can use the AWS Command Line Interface (AWS CLI). AWS CLI enables you to control multiple AWS services directly from the command line within one tool. AWS CLI is available for users on Windows, macOS, and Linux. 




AWS CloudFormation – infrastcuture as Code (IaC) tool used to define a wide variety of AWS resources in a declarative way using JSON or YAML text-based documents called CLOUD FORMATION TEMPLATE

AWS CloudFormation
With AWS CloudFormation, you can treat your infrastructure as code. This means that you can build an environment by writing lines of code instead of using the AWS Management Console to individually provision resources.
AWS CloudFormation provisions your resources in a safe, repeatable manner, enabling you to frequently build your infrastructure and applications without having to perform manual actions. It determines the right operations to perform when managing your stack and rolls back changes automatically if it detects errors.

AWS Elastic Beanstalk
With AWS Elastic Beanstalk, you provide code and configuration settings, and Elastic Beanstalk deploys the resources necessary to perform the following tasks:
	· Adjust capacity
	· Load balancing
	· Automatic scaling
	· Application health monitoring












VPC let you provision a logically isolated section of the aws cloud where you can launch aws resources in a virtual network that you define. These resources can be public facing or private with no internet access
 
VPC allow you to define your private IP range for your aws resources and you place things like ec2 instances and ELBs inside your VPC. 
You place them into different SUBNETS. Subnets are chunkcs of IP addresses in your VPC that allow you to group resources together.


Amazon VPC enables you to provision an isolated section of the AWS Cloud. In this isolated section, you can launch resources in a virtual network that you define. Within a virtual private cloud (VPC), you can organize your resources into subnets. A subnet is a section of a VPC that can contain resources such as Amazon EC2 instances.

 


Internet gateway
To allow public traffic from the internet to access your VPC, you attach an internet gateway to the VPC.
An internet gateway is a connection between a VPC and the internet. You can think of an internet gateway as being similar to a doorway that customers use to enter the coffee shop. Without an internet gateway, no one can access the resources within your VPC.



Virtual private gateway
To access private resources in a VPC, you can use a virtual private gateway. 
Here’s an example of how a virtual private gateway works. You can think of the internet as the road between your home and the coffee shop. Suppose that you are traveling on this road with a bodyguard to protect you. You are still using the same road as other customers, but with an extra layer of protection. 
The bodyguard is like a virtual private network (VPN) connection that encrypts (or protects) your internet traffic from all the other requests around it. 
The virtual private gateway is the component that allows protected internet traffic to enter into the VPC. Even though your connection to the coffee shop has extra protection, traffic jams are possible because you’re using the same road as other customers. 

✅ 1. Internet Gateway (IGW)
	• Purpose:
Allows public traffic (IPv4/IPv6) from the internet to access resources in your VPC.
	• Use Case:
When you want instances (like EC2) in a public subnet to:
		○ Access the internet (e.g., download updates, serve a website).
		○ Be accessed from the internet (e.g., web server, public API).
	• Key Points:
		○ Attach to VPC.
		○ Route Table must point to IGW for public subnets (0.0.0.0/0 → IGW).
		○ Instance needs a public IP or Elastic IP.

✅ 2. Virtual Private Gateway (VGW)
	• Purpose:
Allows private, secure connections between your VPC and your on-premises network or another AWS environment using:
		○ VPN Connection (IPSec)
		○ AWS Direct Connect
	• Use Case:
When you have a corporate network (data center) and you want to:
		○ Access private resources in your VPC securely.
		○ Extend your internal network into AWS.
	• Key Points:
		○ VGW is attached to VPC.
		○ Used with VPN or Direct Connect.
		○ No public internet involved — it's a private, encrypted tunnel.

AWS Direct Connect
AWS Direct Connect(opens in a new tab) is a service that lets you to establish a dedicated private connection between your data center and a VPC.  
Suppose that there is an apartment building with a hallway directly linking the building to the coffee shop. Only the residents of the apartment building can travel through this hallway. 
This private hallway provides the same type of dedicated connection as AWS Direct Connect. Residents are able to get into the coffee shop without needing to use the public road shared with other customers. 



Network ACL (Access Control List) – this checks to see if the packet has permissions to either leave or enter the subnet based on who it was sent from and how its trying to communicate. Its like a passport control officer.
However, it doesn’t evalute if a packet can reach a specific EC2 instances.


Security group is stateful – meaning it has some memory when it comes to who to allow in or out, and network ACL is stateless – it doesn’t remember nothing. It checks every packet every sinle packet.s

 
Subnets
A subnet is a section of a VPC in which you can group resources based on security or operational needs. Subnets can be public or private. 


Public subnets contain resources that need to be accessible by the public, such as an online store’s website.
Private subnets contain resources that should be accessible only through your private network, such as a database that contains customers’ personal information and order histories. 
In a VPC, subnets can communicate with each other. For example, you might have an application that involves Amazon EC2 instances in a public subnet communicating with databases that are located in a private subnet.

Network ACLs
A network ACL is a virtual firewall that controls inbound and outbound traffic at the subnet level.
For example, step outside of the coffee shop and imagine that you are in an airport. In the airport, travelers are trying to enter into a different country. You can think of the travelers as packets and the passport control officer as a network ACL. The passport control officer checks travelers’ credentials when they are both entering and exiting out of the country. If a traveler is on an approved list, they are able to get through. However, if they are not on the approved list or are explicitly on a list of banned travelers, they cannot come in.

Stateless packet filtering
Network ACLs perform stateless packet filtering. They remember nothing and check packets that cross the subnet border each way: inbound and outbound. 

Security groups
A security group is a virtual firewall that controls inbound and outbound traffic for an Amazon EC2 instance.
By default, a security group denies all inbound traffic and allows all outbound traffic. You can add custom rules to configure which traffic should be allowed; any other traffic would then be denied

Stateful packet filtering
Security groups perform stateful packet filtering. They remember previous decisions made for incoming packets.


Amazon Route 53
Amazon Route 53(opens in a new tab) is a DNS web service. It gives developers and businesses a reliable way to route end users to internet applications hosted in AWS. 
Amazon Route 53 connects user requests to infrastructure running in AWS (such as Amazon EC2 instances and load balancers). It can route users to infrastructure outside of AWS.

Instance stores
Block-level storage volumes behave like physical hard drives.
An instance store(opens in a new tab) provides temporary block-level storage for an Amazon EC2 instance. An instance store is disk storage that is physically attached to the host computer for an EC2 instance, and therefore has the same lifespan as the instance. 

Amazon Elastic Block Store (Amazon EBS)(opens in a new tab) is a service that provides block-level storage volumes that you can use with Amazon EC2 instances
To create an EBS volume, you define the configuration (such as volume size and type) and provision it. After you create an EBS volume, it can attach to an Amazon EC2 instance.

An EBS snapshot(opens in a new tab) is an incremental backup. This means that the first backup taken of a volume copies all the data. For subsequent backups, only the blocks of data that have changed since the most recent snapshot are saved. 
Incremental backups are different from full backups, in which all the data in a storage volume copies each time a backup occurs. The full backup includes data that has not changed since the most recent backup.



S3.
-Store data as objects
-Store Objects in Buckets
-Upload maximum object size of 5TB
-Version Objects
-Create Multiple Buckets
In object storage, each object consists of data, metadata, and a key.
The data might be an image, video, text document, or any other type of file. Metadata contains information about what the data is, how it is used, the object size, and so on. An object’s key is its unique identifier.


Amazon Simple Storage Service (Amazon S3)
Amazon Simple Storage Service (Amazon S3)(opens in a new tab) is a service that provides object-level storage. Amazon S3 stores data as objects in buckets.


S3 Classses

	• S3 Standard
	• S3 Standard-Infrequent Access (S3 Standard-IA)
	• S3 One Zone-Infreqeunt Access (S3 One Zone-IA)
	• S3 Intelligent-Tiering
	• S3 Glacier Instant Retreival
	• S3 Glacier Flexible Retrieval
	• S3 Glacier Deep Archive
	• S3 Outposts


S3 Glacier (and its versions) = "Archive storage".
Meaning:
	• Glacier = for long-term storage of data you don't need to access often.
	• It's very cheap compared to Standard/IA.

S3 Standard
	· Designed for frequently accessed data
	· Stores data in a minimum of three Availability Zones
Amazon S3 Standard provides high availability for objects. This makes it a good choice for a wide range of use cases, such as websites, content distribution, and data analytics. 


S3 Standard-Infrequent Access (S3 Standard-IA)
	· Ideal for infrequently accessed data
	· Similar to Amazon S3 Standard but has a lower storage price and higher retrieval price
Amazon S3 Standard-IA is ideal for data infrequently accessed but requires high availability when needed. 

S3 One Zone-Infrequent Access (S3 One Zone-IA)
	· Stores data in a single Availability Zone
	· Has a lower storage price than Amazon S3 Standard-IA
Compared to S3 Standard and S3 Standard-IA, which store data in a minimum of three Availability Zones, S3 One Zone-IA stores data in a single Availability Zone. 

S3 Intelligent-Tiering
	· Ideal for data with unknown or changing access patterns
	· Requires a small monthly monitoring and automation fee per object
In the S3 Intelligent-Tiering storage class, Amazon S3 monitors objects’ access patterns.

 
S3 Glacier Instant Retrieval
	· Works well for archived data that requires immediate access
	· Can retrieve objects within a few milliseconds
When you decide between the options for archival storage, consider how quickly you must retrieve the archived objects. You can retrieve objects stored in the S3 Glacier Instant Retrieval storage class within milliseconds, with the same performance as S3 Standard.

S3 Glacier Flexible Retrieval
	· Low-cost storage designed for data archiving
	· Able to retrieve objects within a few minutes to hours
S3 Glacier Flexible Retrieval is a low-cost storage class that is ideal for data archiving. For example, you might use this storage class to store archived customer records or older photos and video files. You can retrieve your data from S3 Glacier Flexible Retrieval from 1 minute to 12 hours.

S3 Glacier Deep Archive
	· Lowest-cost object storage class ideal for archiving
	· Able to retrieve objects within 12 hours
S3 Deep Archive supports long-term retention and digital preservation for data that might be accessed once or twice in a year. This storage class is the lowest-cost storage in the AWS Cloud, with data retrieval from 12 to 48 hours. All objects from this storage class are replicated and stored across at least three geographically dispersed Availability Zones.

 
S3 Outposts
	· Creates S3 buckets on Amazon S3 Outposts
	· Makes it easier to retrieve, store, and access data on AWS Outposts
Amazon S3 Outposts delivers object storage to your on-premises AWS Outposts environment. Amazon S3 Outposts is designed to store data durably and redundantly across multiple devices and servers on your Outposts. It works well for workloads with local data residency requirements that must satisfy demanding performance needs by keeping data close to on-premises applications.

													


File storage
In file storage, multiple clients (such as users, applications, servers, and so on) can access data that is stored in shared file folders.

Amazon Elastic File System (Amazon EFS)(opens in a new tab) is a scalable file system used with AWS Cloud services and on-premises resources. As you add and remove files, Amazon EFS grows and shrinks automatically. It can scale on demand to petabytes without disrupting applications. 

Relational databases
In a relational database, data is stored in a way that relates it to other pieces of data. 
Relational databases use structured query language (SQL) to store and query data. This approach allows data to be stored in an easily understandable, consistent, and scalable way.

Amazon Relational Database Service
Amazon Relational Database Service (Amazon RDS)(opens in a new tab) is a service that enables you to run relational databases in the AWS Cloud.
Amazon RDS is a managed service that automates tasks such as hardware provisioning, database setup, patching, and backups.

Amazon RDS database engines
Amazon RDS is available on six database engines, which optimize for memory, performance, or input/output (I/O). Supported database engines include:
	· Amazon Aurora
	· PostgreSQL
	· MySQL
	· MariaDB
	· Oracle Database
	· Microsoft SQL Server

Amazon Aurora
Amazon Aurora(opens in a new tab) is an enterprise-class relational database. It is compatible with MySQL and PostgreSQL relational databases. It is up to five times faster than standard MySQL databases and up to three times faster than standard PostgreSQL databases.

Non-relational databases
In a nonrelational database, you create tables. A table is a place where you can store and query data.
Nonrelational databases are sometimes referred to as “NoSQL databases” because they use structures other than rows and columns to organize data

Amazon DynamoDB
Amazon DynamoDB(opens in a new tab) is a key-value database service. It delivers single-digit millisecond performance at any scale.

Amazon Redshift
Amazon Redshift(opens in a new tab) is a data warehousing service that you can use for big data analytics. It offers the ability to collect data from many sources and helps you to understand relationships and trends across your data.

AWS Database Migration Service (AWS DMS)
AWS Database Migration Service (AWS DMS)(opens in a new tab) enables you to migrate relational databases, nonrelational databases, and other types of data stores.
Other use cases for AWS DMS
To review other use cases for AWS DMS, select each of the following flashcards.
Development and test database migrations
Enabling developers to test applications against production data without affecting production users
Database consolidation
Combining several databases into a single database
Continuous replication
Sending ongoing copies of your data to other target sources instead of doing a one-time migration


Amazon DocumentDB(opens in a new tab) is a document database service that supports MongoDB workloads. (MongoDB is a document database program.)

Amazon Neptune
Amazon Neptune(opens in a new tab) is a graph database service. 

 
Amazon Quantum Ledger Database (Amazon QLDB)
Amazon Quantum Ledger Database (Amazon QLDB)(opens in a new tab) is a ledger database service. 

Amazon Managed Blockchain
Amazon Managed Blockchain(opens in a new tab) is a service that you can use to create and manage blockchain networks with open-source frameworks. 

Amazon ElastiCache
Amazon ElastiCache(opens in a new tab) is a service that adds caching layers on top of your databases to help improve the read times of common requests. 

Amazon DynamoDB Accelerator
Amazon DynamoDB Accelerator (DAX)(opens in a new tab) is an in-memory cache for DynamoDB. 
